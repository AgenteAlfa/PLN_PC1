{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "import re\n",
    "import time\n",
    "\n",
    "def SimplificarSTR(input:str):\n",
    "      return \"<s>\" if input == \"<s>\" else \"</s>\" if input == \"</s>\" else re.sub( r\"[^a-z0-9 ]+\",\"\", input.lower(),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAR CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 esimo ngrama con 12384 tokens\n",
      "2 esimo ngrama con 98965 tokens\n",
      "3 esimo ngrama con 166844 tokens\n",
      "4 esimo ngrama con 190525 tokens\n",
      "5 esimo ngrama con 195613 tokens\n",
      "1 esimo ngrama con 24716 tokens\n",
      "2 esimo ngrama con 156255 tokens\n",
      "3 esimo ngrama con 275282 tokens\n",
      "4 esimo ngrama con 314913 tokens\n",
      "5 esimo ngrama con 323987 tokens\n",
      "1 esimo ngrama con 286776 tokens\n",
      "2 esimo ngrama con 5090206 tokens\n",
      "3 esimo ngrama con 14777418 tokens\n",
      "4 esimo ngrama con 21887428 tokens\n",
      "5 esimo ngrama con 24567886 tokens\n"
     ]
    }
   ],
   "source": [
    "import corpusador as corpu\n",
    "corpu.CorpusProcesador(corpu.getSmallCorpus(), \"data/corpus_1\")      \n",
    "corpu.CorpusProcesador(corpu.getMedCorpus(), \"data/corpus_2\")\n",
    "#corpu.CorpusProcesador(corpu.getBigCorpus(), \"data/corpus_3\") #CORPUS MUY PESADO SE EXPANDEA A 1.24GB\n",
    "#BAJAR DE https://www.kaggle.com/datasets/jannesklaas/scifi-stories-text-corpus y \n",
    "#agregar a la carpeta como big_corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula para k-grama:\n",
    "$$P_{KN}(W_{n}|W_{n-1}...W_{n-k}) = \\frac{max(C(W_{n-k}...W_{n}) - d, 0)}{W_{n-k}...W_{n - 1}} + \\lambda(W_{n-k}..W_{n-1})P_{KN}(W_{n}|W_{n-1}...W_{n-k + 1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngramador:\n",
    "    D = 0.75\n",
    "    def __init__(self, dir_corpus, n = 3):\n",
    "        self.nN = n\n",
    "        #tokenized_corpus = self.tokenize_corpus(corpus)\n",
    "        #self.lstNGram = [self.count_ngrams(tokenized_corpus, i + 1) for i in range(self.nN)]\n",
    "        #self.continuation_counts = self.compute_unique_context_counts(self.lstNGram[1])\n",
    "        #self.total_continuations = len(self.lstNGram[1])\n",
    "        self.dic, self.revdic = self.LeerDiccionario(dir_corpus)\n",
    "        self.recuerdos = {}\n",
    "        self.lstNGram = []\n",
    "        for i in range(self.nN):\n",
    "            self.lstNGram.append(self.LeerNgrama(dir_corpus, i))\n",
    "            print(f\"{i+1} esimo ngrama con {len(self.lstNGram[i])} tokens\")\n",
    "            \n",
    "        self.continuation_counts = self.compute_unique_context_counts(self.lstNGram[1])\n",
    "        self.total_continuations = len(self.lstNGram[1])\n",
    "        \n",
    "        \n",
    "    def LeerDiccionario(self, dir_corpus):\n",
    "        file = open(dir_corpus + \"/dic.txt\", \"r\")\n",
    "        lines = file.readlines()\n",
    "        dic = {}\n",
    "        rev_dic = {}\n",
    "        \n",
    "        for line in lines:\n",
    "            sp = line.replace(\"\\n\", \"\").split(\":\")\n",
    "            dic[sp[0]] = int(sp[1])\n",
    "            rev_dic[int(sp[1])] = sp[0]\n",
    "        file.close()\n",
    "        return dic, rev_dic\n",
    "    def LeerNgrama(self, dir_corpus, i):\n",
    "        t0 = round(time.time() * 1000)\n",
    "        file = open(dir_corpus + f\"/NG{i + 1}.txt\", \"r\")\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "        ngram_counts = {}\n",
    "        t1 = round(time.time() * 1000)\n",
    "        for line in lines:\n",
    "            sp = line.split(\":\")\n",
    "            sp0 = sp[0].split()\n",
    "            sp0 = tuple([int(num) for num in sp0])\n",
    "            sp1 = int(sp[1].replace(\"\\n\", \"\"))\n",
    "            ngram_counts[sp0] = sp1     \n",
    "        t2= round(time.time() * 1000)\n",
    "        print(f\"Tiempos 0-1 : {t1 - t0}ms - Tiempos 1-2 : {t2 - t1}ms\")\n",
    "        return ngram_counts\n",
    "      \n",
    "    def tokenize_corpus(self, corpus: List[str]) -> List[List[str]]: \n",
    "        return [ ['<s>'] + sentence.lower().split() + ['</s>'] for sentence in corpus]\n",
    "\n",
    "    def count_ngrams(self, tokenized_corpus: List[List[str]], n: int) -> Dict[Tuple[str, ...], int]:\n",
    "        ngram_counts = collections.Counter()\n",
    "        for tokens in tokenized_corpus:\n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                ngram = tuple(tokens[i:i + n])\n",
    "                ngram_counts[ngram] += 1\n",
    "        return ngram_counts\n",
    "    \n",
    "    #Cálculo de la probabilidad de continuación\n",
    "    def continuation_probability(self, word: str, continuation_counts: Dict[str, int], total_continuations: int) -> float:\n",
    "        return continuation_counts[word] / total_continuations\n",
    "\n",
    "    #Cálculo del factor de normalización\n",
    "    #context NGRAMA (P1,P2,P3...)\n",
    "    #ngram_counts NGRAMAS\n",
    "    def flambda(self, context: Tuple[str, ...], ngram_counts: Dict[Tuple[str, ...], int], lower_order_counts: Dict[Tuple[str, ...], int]) -> float:\n",
    "        #context_count = sum([count for ngram, count in ngram_counts.items() if ngram[:-1] == context])\n",
    "        #mcontext = lower_order_counts[context]\n",
    "        #print(f\"context_count: {context_count} = {mcontext}\")\n",
    "        context_count = lower_order_counts[context]\n",
    "        if (context in self.recuerdos.keys()):\n",
    "            sum = self.recuerdos[context]\n",
    "        else:\n",
    "            sum = 0\n",
    "            for ngram in ngram_counts.keys():\n",
    "                sum += 1 if ngram[:-1] == context else 0\n",
    "            self.recuerdos[context] = sum\n",
    "        #unique_continuations = len([1 for ngram in ngram_counts if ngram[:-1] == context])\n",
    "        #munique = sum\n",
    "        unique_continuations = sum\n",
    "        #print(f\"unique_continuations: {unique_continuations} = {munique}\")\n",
    "        return (Ngramador.D * unique_continuations) / context_count if context_count > 0 else 0\n",
    "    \n",
    "    #Cálculo de conteos de contextos unicos (para probabilidad de continuación)\n",
    "    def compute_unique_context_counts(self, bigram_counts: Dict[Tuple[str, str], int]) -> Dict[str, int]:\n",
    "        continuation_counts = collections.Counter()\n",
    "        for (w_prev, w_next) in bigram_counts:\n",
    "            continuation_counts[w_next] += 1\n",
    "        return continuation_counts\n",
    "\n",
    "    def destraducir(self, tup):\n",
    "        return tuple([self.revdic[t] for t in tup])\n",
    "    \n",
    "    def PKN(self, ngram: Tuple):\n",
    "        N = len(ngram) - 1\n",
    "        \n",
    "        NGN_count = self.lstNGram[N].get(ngram, 0)\n",
    "        NGNl_count = self.lstNGram[N - 1].get(ngram[:-1], 0)\n",
    "        #print(f\"{N}-> NG{ngram} Buscando : {ngram[:-1]} = {self.destraducir(ngram[:-1])} EN NG{N} ----> {NGNl_count}\")\n",
    "        #print(f\"TIPOS : NGN {type(ngram[:-1][0])} - NGN_LST {type(list(self.lstNGram[N - 1].keys())[0][0])}\")\n",
    "        if(N == 0): \n",
    "            res = self.continuation_probability(ngram[0], self.continuation_counts, self.total_continuations)\n",
    "            #print(f\"RES N1 : {res}\")\n",
    "            return res\n",
    "        if NGNl_count > 0:\n",
    "            \n",
    "            t0 = round(time.time() * 1000)\n",
    "            #print(f\"ngl = {ngram[:-1]}, con N = {len(list(self.lstNGram[N - 1].keys())[0])}\")\n",
    "            fl = self.flambda(ngram[:-1], self.lstNGram[N], self.lstNGram[N - 1])\n",
    "            t1 = round(time.time() * 1000)\n",
    "            #print(f\"flambda :  analizado para {ngram[:-1]} con {t1 - t0}ms\")\n",
    "            #print(f\"PKN{len(ngram)} - IFEA LLAMADO\")\n",
    "            res = max(NGN_count - Ngramador.D, 0) / NGNl_count + fl * self.PKN(ngram[1:])\n",
    "            #t1 = round(time.time() * 1000)\n",
    "        else:\n",
    "            #print(f\"PKN{len(ngram)} - ELSE LLAMADO\")\n",
    "            res = self.PKN(ngram[1:])\n",
    "            #t1 = round(time.time() * 1000)\n",
    "        #print(f\"RES : {res}\")\n",
    "        #t2 = round(time.time() * 1000)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def sentence_probability(self, sentence: str):\n",
    "        \n",
    "        tokens = ['<s>'] + sentence.lower().split() + ['</s>']\n",
    "        print(f\"N-Grama : {tokens}\")\n",
    "        tokens = [int(self.dic.get(SimplificarSTR(t), -1)) for t in tokens]\n",
    "        print(f\"N-Grama traducido: {tokens}\")\n",
    "        \n",
    "        sum = 0.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.nN + 1):\n",
    "            t0 = round(time.time() * 1000)\n",
    "            ngrama = tuple([tokens[i + k] for k in range(self.nN)])\n",
    "            prob = self.PKN(ngrama)\n",
    "            t1 = round(time.time() * 1000)\n",
    "            #print(f\"N-Grama : {ngrama} analizado con {t1 - t0}ms\")\n",
    "            #print(prob)\n",
    "            sum += math.log2(prob) if prob > 0 else float('-inf')\n",
    "            #probability_log_sum += math.log(prob) if prob > 0 else float('-inf')\n",
    "            \n",
    "        #return math.exp(sum)\n",
    "        return 2**(-1 / len(tokens) * sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS PEQUEÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempos 0-1 : 1ms - Tiempos 1-2 : 7ms\n",
      "1 esimo ngrama con 12384 tokens\n",
      "Tiempos 0-1 : 9ms - Tiempos 1-2 : 71ms\n",
      "2 esimo ngrama con 98965 tokens\n",
      "Tiempos 0-1 : 15ms - Tiempos 1-2 : 133ms\n",
      "3 esimo ngrama con 166844 tokens\n",
      "Tiempos 0-1 : 19ms - Tiempos 1-2 : 166ms\n",
      "4 esimo ngrama con 190525 tokens\n",
      "Tiempos 0-1 : 16ms - Tiempos 1-2 : 177ms\n",
      "5 esimo ngrama con 195613 tokens\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'of', 'their', 'substitute', 'for', 'speech', 'in', 'a', 'singular', 'method', '</s>']\n",
      "N-Grama traducido: [12382, 48, 764, 5901, 181, 2906, 21, 13, 7727, 4382, 12383]\n",
      "La perplejidad de la oración 'of their substitute for speech in a singular method' es: 45.66\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'new', 'york', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [12382, 665, 1692, 3, 85, 2693, 12383]\n",
      "La perplejidad de la oración 'new york is to big' es: 17.27\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'york', 'town', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [12382, 1692, 3036, 3, 85, 2693, 12383]\n",
      "La perplejidad de la oración 'york town is to big' es: 19.06\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'this', 'current', 'acquired', 'a', 'monstrous', 'velocity', '</s>']\n",
      "N-Grama traducido: [12382, 23, 4027, 2940, 13, -1, 2132, 12383]\n",
      "La perplejidad de la oración 'this current acquired a monstrous velocity' es: inf\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'el', 'pollito', 'pio', 'el', 'pollito', 'pio', '</s>']\n",
      "N-Grama traducido: [12382, 5043, -1, -1, 5043, -1, -1, 12383]\n",
      "La perplejidad de la oración 'el pollito pio el pollito pio' es: inf\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_corpus = \"data/corpus_1\"\n",
    "ngdor = Ngramador(dir_corpus, n= 5)\n",
    "print(\"------------------------------------------------\")\n",
    "test = [\"of their substitute for speech in a singular method\", \n",
    "        \"new york is to big\", \n",
    "        \"york town is to big\",\n",
    "        \"this current acquired a monstrous velocity\",\n",
    "        \"el pollito pio el pollito pio\"]\n",
    "\n",
    "for t in test:\n",
    "      p = ngdor.sentence_probability(t)\n",
    "      print(f\"La perplejidad de la oración '{t}' es: {p:.4n}\")\n",
    "      print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS MEDIANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempos 0-1 : 2ms - Tiempos 1-2 : 15ms\n",
      "1 esimo ngrama con 24716 tokens\n",
      "Tiempos 0-1 : 15ms - Tiempos 1-2 : 118ms\n",
      "2 esimo ngrama con 156255 tokens\n",
      "Tiempos 0-1 : 23ms - Tiempos 1-2 : 197ms\n",
      "3 esimo ngrama con 275282 tokens\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'of', 'their', 'substitute', 'for', 'speech', 'in', 'a', 'singular', 'method', '</s>']\n",
      "N-Grama traducido: [24714, 3, 623, 13505, 44, 2185, 5, 29, 1084, 6197, 24715]\n",
      "La perplejidad de la oración 'of their substitute for speech in a singular method' es: 27.8\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'new', 'york', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [24714, 1302, 7212, 256, 20, 4638, 24715]\n",
      "La perplejidad de la oración 'new york is to big' es: 91.39\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'york', 'town', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [24714, 7212, 3221, 256, 20, 4638, 24715]\n",
      "La perplejidad de la oración 'york town is to big' es: 211.7\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'this', 'current', 'acquired', 'a', 'monstrous', 'velocity', '</s>']\n",
      "N-Grama traducido: [24714, 65, 458, 462, 29, 463, 464, 24715]\n",
      "La perplejidad de la oración 'this current acquired a monstrous velocity' es: 18.08\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'a', 'big', 'tower', 'in', 'the', 'sea', '</s>']\n",
      "N-Grama traducido: [24714, 29, 4638, 2639, 5, 1, 269, 24715]\n",
      "La perplejidad de la oración 'a big tower in the sea' es: 162.8\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_corpus = \"data/corpus_2\"\n",
    "ngdor = Ngramador(dir_corpus, n= 3)\n",
    "print(\"------------------------------------------------\")\n",
    "test = [\"of their substitute for speech in a singular method\", \n",
    "        \"new york is to big\", \n",
    "        \"york town is to big\",\n",
    "        \"this current acquired a monstrous velocity\",\n",
    "        \"a big tower in the sea\"]\n",
    "\n",
    "for t in test:\n",
    "      p = ngdor.sentence_probability(t)\n",
    "      print(f\"La perplejidad de la oración '{t}' es: {p:.4n}\")\n",
    "      print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS GRANDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempos 0-1 : 21ms - Tiempos 1-2 : 126ms\n",
      "1 esimo ngrama con 286776 tokens\n",
      "Tiempos 0-1 : 411ms - Tiempos 1-2 : 3520ms\n",
      "2 esimo ngrama con 5090206 tokens\n",
      "Tiempos 0-1 : 1165ms - Tiempos 1-2 : 12793ms\n",
      "3 esimo ngrama con 14777418 tokens\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'of', 'their', 'substitute', 'for', 'speech', 'in', 'a', 'singular', 'method', '</s>']\n",
      "N-Grama traducido: [286774, 46, 120, 7515, 24, 10757, 37, 60, 37062, 1685, 286775]\n",
      "La perplejidad de la oración 'of their substitute for speech in a singular method' es: 952.5\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'new', 'york', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [286774, 4, 19, 10, 55, 983, 286775]\n",
      "La perplejidad de la oración 'new york is to big' es: 295.3\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'york', 'town', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [286774, 19, 2004, 10, 55, 983, 286775]\n",
      "La perplejidad de la oración 'york town is to big' es: 936.8\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'this', 'current', 'acquired', 'a', 'monstrous', 'velocity', '</s>']\n",
      "N-Grama traducido: [286774, 49, 8313, 5851, 60, 2307, 4621, 286775]\n",
      "La perplejidad de la oración 'this current acquired a monstrous velocity' es: 1707\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_corpus = \"data/corpus_3\"\n",
    "ngdor = Ngramador(dir_corpus, n= 3)\n",
    "print(\"------------------------------------------------\")\n",
    "test = [\"of their substitute for speech in a singular method\", \n",
    "        \"new york is to big\", \n",
    "        \"york town is to big\",\n",
    "        \"this current acquired a monstrous velocity\"]\n",
    "\n",
    "for t in test:\n",
    "      p = ngdor.sentence_probability(t)\n",
    "      print(f\"La perplejidad de la oración '{t}' es: {p:.4n}\")\n",
    "      print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
