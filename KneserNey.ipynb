{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "import re\n",
    "\n",
    "def SimplificarSTR(input:str):\n",
    "      return \"<s>\" if input == \"<s>\" else \"</s>\" if input == \"</s>\" else re.sub( r\"[^a-z0-9 ]+\",\"\", input.lower(),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAR CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 esimo ngrama con 12384 tokens\n",
      "2 esimo ngrama con 98965 tokens\n",
      "3 esimo ngrama con 166844 tokens\n",
      "4 esimo ngrama con 190525 tokens\n",
      "5 esimo ngrama con 195613 tokens\n",
      "1 esimo ngrama con 24716 tokens\n",
      "2 esimo ngrama con 156255 tokens\n",
      "3 esimo ngrama con 275282 tokens\n",
      "4 esimo ngrama con 314913 tokens\n",
      "5 esimo ngrama con 323987 tokens\n"
     ]
    }
   ],
   "source": [
    "import corpusador as corpu\n",
    "corpu.CorpusProcesador(corpu.getSmallCorpus(), \"data/corpus_1\")      \n",
    "corpu.CorpusProcesador(corpu.getMedCorpus(), \"data/corpus_2\")\n",
    "#corpu.CorpusProcesador(corpu.getBigCorpus(), \"data/corpus_3\") #CORPUS MUY PESADO SE EXPANDEA A 1.24GB\n",
    "#BAJAR DE https://www.kaggle.com/datasets/jannesklaas/scifi-stories-text-corpus y \n",
    "#agregar a la carpeta como big_corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula para k-grama:\n",
    "$$P_{KN}(W_{n}|W_{n-1}...W_{n-k}) = \\frac{max(C(W_{n-k}...W_{n}) - d, 0)}{W_{n-k}...W_{n - 1}} + \\lambda(W_{n-k}..W_{n-1})P_{KN}(W_{n}|W_{n-1}...W_{n-k + 1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngramador:\n",
    "    D = 0.75\n",
    "    def __init__(self, dir_corpus, n = 3):\n",
    "        self.nN = n\n",
    "        #tokenized_corpus = self.tokenize_corpus(corpus)\n",
    "        #self.lstNGram = [self.count_ngrams(tokenized_corpus, i + 1) for i in range(self.nN)]\n",
    "        #self.continuation_counts = self.compute_unique_context_counts(self.lstNGram[1])\n",
    "        #self.total_continuations = len(self.lstNGram[1])\n",
    "        self.dic, self.revdic = self.LeerDiccionario(dir_corpus)\n",
    "        self.lstNGram = []\n",
    "        for i in range(self.nN):\n",
    "            self.lstNGram.append(self.LeerNgrama(dir_corpus, i))\n",
    "            print(f\"{i+1} esimo ngrama con {len(self.lstNGram[i])} tokens\")\n",
    "            \n",
    "        self.continuation_counts = self.compute_unique_context_counts(self.lstNGram[1])\n",
    "        self.total_continuations = len(self.lstNGram[1])\n",
    "        \n",
    "        \n",
    "    def LeerDiccionario(self, dir_corpus):\n",
    "        file = open(dir_corpus + \"/dic.txt\", \"r\")\n",
    "        lines = file.readlines()\n",
    "        dic = {}\n",
    "        rev_dic = {}\n",
    "        \n",
    "        for line in lines:\n",
    "            sp = line.replace(\"\\n\", \"\").split(\":\")\n",
    "            dic[sp[0]] = int(sp[1])\n",
    "            rev_dic[int(sp[1])] = sp[0]\n",
    "        file.close()\n",
    "        return dic, rev_dic  \n",
    "    def LeerNgrama(self, dir_corpus, i):\n",
    "        file = open(dir_corpus + f\"/NG{i + 1}.txt\", \"r\")\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "        ngram_counts = {}\n",
    "        for line in lines:\n",
    "            sp = line.split(\":\")\n",
    "            sp0 = sp[0].split()\n",
    "            sp0 = tuple([int(num) for num in sp0])\n",
    "            sp1 = int(sp[1].replace(\"\\n\", \"\"))\n",
    "            ngram_counts[sp0] = sp1        \n",
    "        return ngram_counts\n",
    "        \n",
    "      \n",
    "    def tokenize_corpus(self, corpus: List[str]) -> List[List[str]]: \n",
    "        return [ ['<s>'] + sentence.lower().split() + ['</s>'] for sentence in corpus]\n",
    "\n",
    "    def count_ngrams(self, tokenized_corpus: List[List[str]], n: int) -> Dict[Tuple[str, ...], int]:\n",
    "        ngram_counts = collections.Counter()\n",
    "        for tokens in tokenized_corpus:\n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                ngram = tuple(tokens[i:i + n])\n",
    "                ngram_counts[ngram] += 1\n",
    "        return ngram_counts\n",
    "    \n",
    "    #Cálculo de la probabilidad de continuación\n",
    "    def continuation_probability(self, word: str, continuation_counts: Dict[str, int], total_continuations: int) -> float:\n",
    "        return continuation_counts[word] / total_continuations\n",
    "\n",
    "    #Cálculo del factor de normalización\n",
    "    def flambda(self, context: Tuple[str, ...], ngram_counts: Dict[Tuple[str, ...], int], lower_order_counts: Dict[Tuple[str, ...], int]) -> float:\n",
    "        context_count = sum([count for ngram, count in ngram_counts.items() if ngram[:-1] == context])\n",
    "        unique_continuations = len([1 for ngram in ngram_counts if ngram[:-1] == context])\n",
    "        return (Ngramador.D * unique_continuations) / context_count if context_count > 0 else 0\n",
    "    \n",
    "    #Cálculo de conteos de contextos unicos (para probabilidad de continuación)\n",
    "    def compute_unique_context_counts(self, bigram_counts: Dict[Tuple[str, str], int]) -> Dict[str, int]:\n",
    "        continuation_counts = collections.Counter()\n",
    "        for (w_prev, w_next) in bigram_counts:\n",
    "            continuation_counts[w_next] += 1\n",
    "        return continuation_counts\n",
    "\n",
    "    def destraducir(self, tup):\n",
    "        return tuple([self.revdic[t] for t in tup])\n",
    "    \n",
    "    def PKN(self, ngram: Tuple):\n",
    "      N = len(ngram) - 1\n",
    "      NGN_count = self.lstNGram[N].get(ngram, 0)\n",
    "      NGNl_count = self.lstNGram[N - 1].get(ngram[:-1], 0)\n",
    "      #print(f\"{N}-> NG{ngram} Buscando : {ngram[:-1]} = {self.destraducir(ngram[:-1])} EN NG{N} ----> {NGNl_count}\")\n",
    "      #print(f\"TIPOS : NGN {type(ngram[:-1][0])} - NGN_LST {type(list(self.lstNGram[N - 1].keys())[0][0])}\")\n",
    "      if(N == 1): return self.continuation_probability(ngram[0], self.continuation_counts, self.total_continuations)\n",
    "      if NGNl_count > 0:\n",
    "            #print(f\"ngl = {ngram[:-1]}, con N = {len(list(self.lstNGram[N - 1].keys())[0])}\")\n",
    "            fl = self.flambda(ngram[:-1], self.lstNGram[N], self.lstNGram[N - 1])\n",
    "            #print(f\"PKN{len(ngram)} - IFEA LLAMADO\")\n",
    "            return max(NGN_count - Ngramador.D, 0) / NGNl_count + fl * self.PKN(ngram[1:])\n",
    "      else:\n",
    "            #print(f\"PKN{len(ngram)} - ELSE LLAMADO\")\n",
    "            return self.PKN(ngram[1:])\n",
    "    \n",
    "    def sentence_probability(self, sentence: str):\n",
    "        \n",
    "        tokens = ['<s>'] + sentence.lower().split() + ['</s>']\n",
    "        print(f\"N-Grama : {tokens}\")\n",
    "        tokens = [int(self.dic.get(SimplificarSTR(t), -1)) for t in tokens]\n",
    "        print(f\"N-Grama traducido: {tokens}\")\n",
    "        \n",
    "        sum = 0.0\n",
    "        for i in range(len(tokens) - self.nN + 1):\n",
    "            ngrama = tuple([tokens[i + k] for k in range(self.nN)])\n",
    "            #print(f\"N-Grama : {ngrama}\")\n",
    "            prob = self.PKN(ngrama)\n",
    "            #print(prob)\n",
    "            sum += math.log2(prob) if prob > 0 else float('-inf')\n",
    "            #probability_log_sum += math.log(prob) if prob > 0 else float('-inf')\n",
    "            \n",
    "        #return math.exp(sum)\n",
    "        return 2**(-1 / len(tokens) * sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS PEQUEÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 esimo ngrama con 12384 tokens\n",
      "2 esimo ngrama con 98965 tokens\n",
      "3 esimo ngrama con 166844 tokens\n",
      "4 esimo ngrama con 190525 tokens\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'of', 'their', 'substitute', 'for', 'speech', 'in', 'a', 'singular', 'method', '</s>']\n",
      "N-Grama traducido: [12382, 48, 764, 5901, 181, 2906, 21, 13, 7727, 4382, 12383]\n",
      "La perplejidad de la oración 'of their substitute for speech in a singular method' es: 291.9\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'new', 'york', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [12382, 665, 1692, 3, 85, 2693, 12383]\n",
      "La perplejidad de la oración 'new york is to big' es: 72.12\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'york', 'town', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [12382, 1692, 3036, 3, 85, 2693, 12383]\n",
      "La perplejidad de la oración 'york town is to big' es: 50.81\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'this', 'current', 'acquired', 'a', 'monstrous', 'velocity', '</s>']\n",
      "N-Grama traducido: [12382, 23, 4027, 2940, 13, -1, 2132, 12383]\n",
      "La perplejidad de la oración 'this current acquired a monstrous velocity' es: inf\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_corpus = \"data/corpus_1\"\n",
    "ngdor = Ngramador(dir_corpus, n= 4)\n",
    "print(\"------------------------------------------------\")\n",
    "test = [\"of their substitute for speech in a singular method\", \n",
    "        \"new york is to big\", \n",
    "        \"york town is to big\",\n",
    "        \"this current acquired a monstrous velocity\"]\n",
    "\n",
    "for t in test:\n",
    "      p = ngdor.sentence_probability(t)\n",
    "      print(f\"La perplejidad de la oración '{t}' es: {p:.4n}\")\n",
    "      print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS MEDIANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 esimo ngrama con 24716 tokens\n",
      "2 esimo ngrama con 156255 tokens\n",
      "3 esimo ngrama con 275282 tokens\n",
      "4 esimo ngrama con 314913 tokens\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'of', 'their', 'substitute', 'for', 'speech', 'in', 'a', 'singular', 'method', '</s>']\n",
      "N-Grama traducido: [24714, 3, 623, 13505, 44, 2185, 5, 29, 1084, 6197, 24715]\n",
      "La perplejidad de la oración 'of their substitute for speech in a singular method' es: 7.262\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'new', 'york', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [24714, 1302, 7212, 256, 20, 4638, 24715]\n",
      "La perplejidad de la oración 'new york is to big' es: 100.6\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'york', 'town', 'is', 'to', 'big', '</s>']\n",
      "N-Grama traducido: [24714, 7212, 3221, 256, 20, 4638, 24715]\n",
      "La perplejidad de la oración 'york town is to big' es: 71.67\n",
      "------------------------------------------------\n",
      "N-Grama : ['<s>', 'this', 'current', 'acquired', 'a', 'monstrous', 'velocity', '</s>']\n",
      "N-Grama traducido: [24714, 65, 458, 462, 29, 463, 464, 24715]\n",
      "La perplejidad de la oración 'this current acquired a monstrous velocity' es: 6.424\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_corpus = \"data/corpus_2\"\n",
    "ngdor = Ngramador(dir_corpus, n= 4)\n",
    "print(\"------------------------------------------------\")\n",
    "test = [\"of their substitute for speech in a singular method\", \n",
    "        \"new york is to big\", \n",
    "        \"york town is to big\",\n",
    "        \"this current acquired a monstrous velocity\"]\n",
    "\n",
    "for t in test:\n",
    "      p = ngdor.sentence_probability(t)\n",
    "      print(f\"La perplejidad de la oración '{t}' es: {p:.4n}\")\n",
    "      print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
